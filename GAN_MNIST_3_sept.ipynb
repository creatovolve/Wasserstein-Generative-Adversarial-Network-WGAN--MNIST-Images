{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import torch, random, numpy as np, os\n",
        "\n",
        "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
      ],
      "metadata": {
        "id": "ol3p3bIi23Vl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # must be before torch import"
      ],
      "metadata": {
        "id": "c2PGp4IxjqM4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KckTafffNJZF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plts\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rLoraCGMNJZG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Fix Python, NumPy, PyTorch RNGs\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Force deterministic behavior in cuDNN\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cuda.matmul.allow_tf32 = False\n",
        "torch.backends.cudnn.allow_tf32 = False\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnijBftpRtnP",
        "outputId": "5d936652-77bf-4f83-e21e-cee9206f9c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sbsvwqfsNJZG"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets.mnist import *\n",
        "\n",
        "def Tansfrm(im):\n",
        "    im = np.array(im).astype(np.float32)\n",
        "    im = (im -128)/255\n",
        "    return torch.tensor(im, requires_grad=False).cuda()\n",
        "\n",
        "dataset_first = MNIST(\"\", train=True, transform= Tansfrm, download=True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfA8C-hkNJZG",
        "outputId": "cd68175e-d2a3-416b-e86a-e11492bd5944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "torch.Size([60000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "dataloader_first = DataLoader(dataset_first, batch_size=2048, shuffle=True)\n",
        "print(dataloader_first.sampler.generator)\n",
        "# <torch._C.Generator object at ...>\n",
        "\n",
        "print(dataset_first.data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EpYI4CvZo2C1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import spectral_norm\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # Input: (1, 28, 28)\n",
        "\n",
        "        # Convolutional layers with spectral norm\n",
        "        self.conv1 = spectral_norm(nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1))   # -> (32, 28, 28)\n",
        "        self.conv2 = spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1))  # -> (64, 28, 28)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # halves each spatial dim\n",
        "\n",
        "        self.conv3 = spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)) # -> (128, 14, 14)\n",
        "        self.conv4 = spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)) # -> (256, 14, 14)\n",
        "\n",
        "        # Fully connected layers with spectral norm\n",
        "        self.fc1 = spectral_norm(nn.Linear(256 * 7 * 7, 512))\n",
        "        self.fc2 = spectral_norm(nn.Linear(512, 128))\n",
        "        self.fc3 = spectral_norm(nn.Linear(128, 1))  # critic output (no sigmoid)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ensure shape (B, 1, 28, 28)\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x), 0.2))   # -> (64, 14, 14)\n",
        "\n",
        "        x = F.leaky_relu(self.conv3(x), 0.2)\n",
        "        x = self.pool(F.leaky_relu(self.conv4(x), 0.2))   # -> (256, 7, 7)\n",
        "\n",
        "        x = x.view(-1, 256 * 7 * 7)  # flatten\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "\n",
        "        x = self.fc3(x)   # final critic score (can be any real number)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N7CmtbaWNJZH"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Linear(5, 32*7*7)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.deconv1 = nn.ConvTranspose2d(32, 16,kernel_size=4, stride = 2, padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose2d(16, 1,kernel_size=4, stride = 2, padding=1)\n",
        "\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.fc(z).view(-1, 32, 7, 7)\n",
        "        x = F.relu(self.bn1(self.deconv1(x)))\n",
        "        x = torch.tanh(self.deconv2(x))   # (batch, 1, 28, 28)\n",
        "        return x.squeeze(1)               # (batch, 28, 28)\n",
        "\n",
        "\n",
        "generator = Generator().cuda()\n",
        "discriminator = Discriminator().cuda()\n",
        "\n",
        "import torch.nn.init as init\n",
        "\n",
        "# You can iterate through all modules and apply initialization\n",
        "for m in generator.modules():\n",
        "      if isinstance(m, nn.Linear):\n",
        "          init.uniform_(m.weight, a=-0.3, b=0.3)\n",
        "          # Optionally initialize biases to zero or a small constant\n",
        "          if m.bias is not None:\n",
        "              init.constant_(m.bias, 0)\n",
        "\n",
        "for m in discriminator.modules():\n",
        "      if isinstance(m, nn.Linear):\n",
        "          init.uniform_(m.weight, a=-0.3, b=0.3)\n",
        "          # Optionally initialize biases to zero or a small constant\n",
        "          if m.bias is not None:\n",
        "              init.constant_(m.bias, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q0GeCXEgNJZI"
      },
      "outputs": [],
      "source": [
        "g_optimizer = torch.optim.SGD(generator.parameters(), lr=0.00001, momentum=0.7, nesterov=True)\n",
        "d_optimizer = torch.optim.SGD(discriminator.parameters(), lr=0.00001, momentum=0.7, nesterov=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r01XbQ63NJZI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images(fake_images, num = 5):\n",
        "\n",
        "    for i in range(num):\n",
        "        img_tensor = fake_images[i]\n",
        "        img = img_tensor.permute(1, 2, 0).detach().cpu().numpy().astype(np.float64)\n",
        "\n",
        "        # Normalize to [0,1]\n",
        "        img = img*255+128\n",
        "        img = torch.min(torch.tensor(255), torch.tensor(img))\n",
        "        # Scale to [0,255] and convert to uint8\n",
        "        img_uint8 = (img).numpy().astype(np.uint8)\n",
        "\n",
        "        plt.imshow(img_uint8[:, :, ::-1])\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7Ipo8UUWN_1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea807088-e481-412b-f210-23f51393939b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2mgpuV12QDao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "907a0efe-618a-4688-d81a-aab5e6597af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discriminator_checkpoint_17540.pth  generator_checkpoint_epoch_17540.pth\n",
            "discriminator_checkpoint_17560.pth  generator_checkpoint_epoch_17560.pth\n",
            "discriminator_checkpoint_17580.pth  generator_checkpoint_epoch_17580.pth\n",
            "discriminator_checkpoint_17600.pth  generator_checkpoint_epoch_17600.pth\n",
            "discriminator_checkpoint_17620.pth  generator_checkpoint_epoch_17620.pth\n",
            "discriminator_checkpoint_17640.pth  generator_checkpoint_epoch_17640.pth\n",
            "discriminator_checkpoint_17660.pth  generator_checkpoint_epoch_17660.pth\n",
            "discriminator_checkpoint_17680.pth  generator_checkpoint_epoch_17680.pth\n",
            "discriminator_checkpoint_17700.pth  generator_checkpoint_epoch_17700.pth\n",
            "discriminator_checkpoint_17720.pth  generator_checkpoint_epoch_17720.pth\n",
            "discriminator_checkpoint_17740.pth  generator_checkpoint_epoch_17740.pth\n",
            "discriminator_checkpoint_17760.pth  generator_checkpoint_epoch_17760.pth\n",
            "discriminator_checkpoint_17780.pth  generator_checkpoint_epoch_17780.pth\n",
            "discriminator_checkpoint_17800.pth  generator_checkpoint_epoch_17800.pth\n",
            "discriminator_checkpoint_20640.pth  generator_checkpoint_epoch_20640.pth\n",
            "discriminator_checkpoint_20720.pth  generator_checkpoint_epoch_20720.pth\n",
            "discriminator_checkpoint_20740.pth  generator_checkpoint_epoch_20740.pth\n",
            "discriminator_checkpoint_20760.pth  generator_checkpoint_epoch_20760.pth\n",
            "discriminator_checkpoint_20780.pth  generator_checkpoint_epoch_20780.pth\n",
            "discriminator_checkpoint_20800.pth  generator_checkpoint_epoch_20800.pth\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/gan_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u6OdHFT83Z2H"
      },
      "outputs": [],
      "source": [
        "# !ls /content/drive/MyDrive\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/gan_models/generator_checkpoint_epoch_20740.pth\", map_location=\"cpu\", weights_only=False)\n",
        "generator.load_state_dict(checkpoint[\"model_state_dict\"], strict=True)\n",
        "g_optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "\n",
        "# Restore RNGs\n",
        "random.setstate(checkpoint[\"python_rng_state\"])\n",
        "np.random.set_state(checkpoint[\"numpy_rng_state\"])\n",
        "torch.set_rng_state(checkpoint[\"rng_state\"])\n",
        "torch.cuda.set_rng_state(checkpoint[\"cuda_rng_state\"])\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/gan_models/discriminator_checkpoint_20740.pth\", map_location=\"cpu\", weights_only=False)\n",
        "discriminator.load_state_dict(checkpoint[\"model_state_dict\"], strict=True)\n",
        "d_optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_iter = iter(dataloader_first)"
      ],
      "metadata": {
        "id": "L3xt_Afrr5nD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_ema_model(model):\n",
        "    \"\"\"Make a deepcopy of model for EMA tracking.\"\"\"\n",
        "    ema_model = copy.deepcopy(model)\n",
        "    for p in ema_model.parameters():\n",
        "        p.requires_grad_(False)\n",
        "    return ema_model"
      ],
      "metadata": {
        "id": "SM97zcv9mbZQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_ema_model(model, ema_model, decay=0.9):\n",
        "    \"\"\"Update EMA model in place.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        msd = model.state_dict()\n",
        "        for k, ema_v in ema_model.state_dict().items():\n",
        "            model_v = msd[k].detach()\n",
        "            if torch.is_floating_point(ema_v):\n",
        "                ema_v.mul_(decay).add_(model_v, alpha=1 - decay)\n",
        "            else:\n",
        "                ema_v.copy_(model_v)\n"
      ],
      "metadata": {
        "id": "ukAV4-qDmcVX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ema_to_model(model, ema_model):\n",
        "    \"\"\"Copy EMA model weights into the actual model.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        for p, ema_p in zip(model.state_dict().values(), ema_model.state_dict().values()):\n",
        "            p.copy_(ema_p)"
      ],
      "metadata": {
        "id": "Bdf6z4XenLfD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ACl8sgJJL6UL"
      },
      "outputs": [],
      "source": [
        "def dump_images(fake_images):\n",
        "    for i in range(fake_images.shape[0]):\n",
        "      img_tensor = fake_images[i]\n",
        "      img = img_tensor.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "      # Normalize to [0,1]\n",
        "      img = img*255+128\n",
        "      img = torch.min(torch.tensor(255), torch.tensor(img))\n",
        "      # Scale to [0,255] and convert to uint8\n",
        "      img_uint8 = (img).numpy().astype(np.uint8)\n",
        "\n",
        "      cv2.imwrite(f\"/content/drive/MyDrive/dump_images/{i}.png\", img_uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXeCBZgfNJZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcd10bf-65ff-4054-a935-3354b73fb18f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved to /content/drive/MyDrive/gan_models/discriminator_checkpoint_20740.pth\n",
            "Epoch starting 20740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3685345404.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  fake_images = torch.tensor(fake_images, requires_grad=False).cuda().detach()\n",
            "/tmp/ipython-input-3685345404.py:89: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
            "  print(\"Discriminator loss in class 0 images {:.7f} and step = {} fake_pred {:.7f} real_pred {:.7f} temp_pred {:.7f} 1q {:.7f} 3q {:.7f}\".format(ls, steps, np.float64(fake_pred.mean().cpu()), np.float64(real_pred.mean().cpu()), np.float64(temp_pred.mean().cpu()), np.float64(temp_pred2.mean().cpu()), np.float64(discriminator(0.75*ims+0.25*fake_images_labeled).mean().cpu())))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator loss in class 0 images 191.5104065 and step = 1 fake_pred 62.9859009 real_pred 46.6182098 temp_pred 55.8993835 1q 59.7100258 3q -264.9158020\n",
            "Discriminator loss in class 0 images -1379.3699951 and step = 2 fake_pred -370.1751709 real_pred -230.0538788 temp_pred -299.9184570 1q -334.7703857 3q -310.9025269\n",
            "Discriminator loss in class 0 images -1552.3791504 and step = 3 fake_pred -429.3036804 real_pred -271.1779785 temp_pred -349.2899475 1q -388.9368896 3q -320.7620850\n",
            "Discriminator loss in class 0 images -1575.7067871 and step = 4 fake_pred -441.8797607 real_pred -280.9449158 temp_pred -360.0115967 1q -400.2639465 3q -318.1065979\n",
            "Discriminator loss in class 0 images -1576.9171143 and step = 5 fake_pred -439.0374146 real_pred -277.7919006 temp_pred -356.9012146 1q -397.2281494 3q -311.5064087\n",
            "Discriminator loss in class 0 images -1570.5412598 and step = 6 fake_pred -432.8453369 real_pred -272.7234802 temp_pred -351.6740417 1q -391.7859192 3q -307.5366821\n",
            "Discriminator loss in class 0 images -1563.3627930 and step = 7 fake_pred -427.6107788 real_pred -268.4422913 temp_pred -347.1226196 1q -387.0264893 3q -304.2805176\n",
            "Discriminator loss in class 0 images -1581.3286133 and step = 8 fake_pred -424.8869629 real_pred -263.7628784 temp_pred -343.2769775 1q -383.6410522 3q -299.7545776\n",
            "Discriminator loss in class 0 images -1562.6333008 and step = 9 fake_pred -419.7247009 real_pred -260.3165894 temp_pred -338.8615723 1q -378.6689758 3q -294.7426147\n",
            "Discriminator loss in class 0 images -1565.8159180 and step = 10 fake_pred -414.7012939 real_pred -255.1778870 temp_pred -334.0069580 1q -373.7926636 3q -291.1992798\n",
            "Discriminator loss in class 0 images -1588.2125244 and step = 11 fake_pred -412.1240234 real_pred -250.5710754 temp_pred -330.6662903 1q -371.0865479 3q -290.1904602\n",
            "Discriminator loss in class 0 images -1603.2471924 and step = 12 fake_pred -413.1416016 real_pred -250.2923889 temp_pred -331.2539978 1q -372.1069946 3q -292.4881897\n",
            "Discriminator loss in class 0 images -1624.2578125 and step = 13 fake_pred -415.8731689 real_pred -250.5629883 temp_pred -332.4170532 1q -373.7708130 3q -291.5469360\n",
            "Discriminator loss in class 0 images -1598.3542480 and step = 14 fake_pred -416.2237244 real_pred -252.7204285 temp_pred -333.1356812 1q -373.5189514 3q -287.1019287\n",
            "Discriminator loss in class 0 images -1572.8344727 and step = 15 fake_pred -408.9584351 real_pred -247.8191833 temp_pred -327.0025024 1q -366.6805115 3q -280.6044922\n",
            "Discriminator loss in class 0 images -1578.6955566 and step = 16 fake_pred -400.0073853 real_pred -238.3266602 temp_pred -317.9220581 1q -357.5536804 3q -271.1521606\n",
            "Discriminator loss in class 0 images -1574.9952393 and step = 17 fake_pred -392.1396484 real_pred -230.5097046 temp_pred -309.9787598 1q -349.4279480 3q -262.0798950\n",
            "Discriminator loss in class 0 images -1579.7690430 and step = 18 fake_pred -381.7593994 real_pred -219.9096375 temp_pred -299.7490845 1q -339.1156311 3q -252.6484070\n",
            "Discriminator loss in class 0 images -1554.7119141 and step = 19 fake_pred -370.2350159 real_pred -211.4802704 temp_pred -290.1965942 1q -328.8619690 3q -247.1050415\n",
            "Discriminator loss in class 0 images -1569.8734131 and step = 20 fake_pred -366.3421936 real_pred -206.7896118 temp_pred -286.7099609 1q -325.8613281 3q -251.2524719\n",
            "Generator loss in class 0 images 848.5151367 and step = 1 \n",
            "Generator loss in class 0 images 812.2357788 and step = 2 \n",
            "Generator loss in class 0 images 764.6855469 and step = 3 \n",
            "Generator loss in class 0 images 708.8345337 and step = 4 \n",
            "Generator loss in class 0 images 650.6909180 and step = 5 \n",
            "Generator loss in class 0 images 591.8563843 and step = 6 \n",
            "Generator loss in class 0 images 535.6384888 and step = 7 \n",
            "Generator loss in class 0 images 474.3611145 and step = 8 \n",
            "Generator loss in class 0 images 420.7452087 and step = 9 \n",
            "Generator loss in class 0 images 370.9425354 and step = 10 \n",
            "Generator loss in class 0 images 331.0893555 and step = 11 \n",
            "Generator loss in class 0 images 305.2835999 and step = 12 \n",
            "Generator loss in class 0 images 286.5207214 and step = 13 \n",
            "Generator loss in class 0 images 272.3214111 and step = 14 \n",
            "Generator loss in class 0 images 261.6946106 and step = 15 \n",
            "Generator loss in class 0 images 250.6003113 and step = 16 \n",
            "Generator loss in class 0 images 245.5170441 and step = 17 \n",
            "Generator loss in class 0 images 235.9197083 and step = 18 \n",
            "Generator loss in class 0 images 230.5067444 and step = 19 \n",
            "Generator loss in class 0 images 224.3446045 and step = 20 \n",
            "Generator loss in class 0 images 219.2291565 and step = 21 \n",
            "Generator loss in class 0 images 213.6938477 and step = 22 \n",
            "Generator loss in class 0 images 210.1450348 and step = 23 \n",
            "Generator loss in class 0 images 205.2942505 and step = 24 \n",
            "Generator loss in class 0 images 201.4685974 and step = 25 \n",
            "Generator loss in class 0 images 197.5513000 and step = 26 \n",
            "Generator loss in class 0 images 194.7708893 and step = 27 \n",
            "Generator loss in class 0 images 189.8092651 and step = 28 \n",
            "Generator loss in class 0 images 186.9525452 and step = 29 \n",
            "Generator loss in class 0 images 184.1311340 and step = 30 \n",
            "Generator loss in class 0 images 180.0836945 and step = 31 \n",
            "Generator loss in class 0 images 176.5741730 and step = 32 \n",
            "Generator loss in class 0 images 174.9647675 and step = 33 \n",
            "Generator loss in class 0 images 172.9590149 and step = 34 \n",
            "Generator loss in class 0 images 170.5060425 and step = 35 \n",
            "Generator loss in class 0 images 166.9555359 and step = 36 \n",
            "Generator loss in class 0 images 165.1642151 and step = 37 \n",
            "Generator loss in class 0 images 163.1793213 and step = 38 \n",
            "Generator loss in class 0 images 160.6358643 and step = 39 \n",
            "Generator loss in class 0 images 159.3813324 and step = 40 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3685345404.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  fake_images = torch.tensor(fake_images, requires_grad=False).cuda().detach()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch starting 20741\n",
            "Discriminator loss in class 0 images 202.7040863 and step = 1 fake_pred -15.7248688 real_pred -33.4686699 temp_pred -23.3707256 1q -19.5831528 3q 106.7780685\n",
            "Discriminator loss in class 0 images -1250.5360107 and step = 2 fake_pred 4.8215561 real_pred 143.9996948 temp_pred 68.7688293 1q 31.2445469 3q 320.1502380\n",
            "Discriminator loss in class 0 images -1611.2330322 and step = 3 fake_pred 190.2107697 real_pred 359.2837830 temp_pred 270.6653748 1q 228.6114197 3q 361.1512451\n",
            "Discriminator loss in class 0 images -1698.7778320 and step = 4 fake_pred 227.1005249 real_pred 406.8980103 temp_pred 312.2838135 1q 266.8466797 3q 368.6935425\n",
            "Discriminator loss in class 0 images -1697.6114502 and step = 5 fake_pred 229.3674622 real_pred 410.1645813 temp_pred 314.3421631 1q 268.9553223 3q 352.4256897\n",
            "Discriminator loss in class 0 images -1719.0651855 and step = 6 fake_pred 217.1934509 real_pred 397.7823792 temp_pred 303.2144775 1q 257.9381714 3q 334.8404541\n",
            "Discriminator loss in class 0 images -1724.5955811 and step = 7 fake_pred 197.8621216 real_pred 379.8016968 temp_pred 284.2388000 1q 238.4606628 3q 309.3395386\n",
            "Discriminator loss in class 0 images -1717.9759521 and step = 8 fake_pred 173.8699951 real_pred 353.5623474 temp_pred 259.7934265 1q 214.8214417 3q 284.3024292\n",
            "Discriminator loss in class 0 images -1712.3845215 and step = 9 fake_pred 151.9968262 real_pred 327.5471802 temp_pred 237.7152405 1q 193.7193909 3q 264.8450317\n",
            "Discriminator loss in class 0 images -1757.6097412 and step = 10 fake_pred 132.8058777 real_pred 311.7392578 temp_pred 221.0303497 1q 176.0077057 3q 252.3933716\n",
            "Discriminator loss in class 0 images -1752.2539062 and step = 11 fake_pred 115.7575531 real_pred 293.6768494 temp_pred 203.9464722 1q 159.0811310 3q 238.0721130\n",
            "Discriminator loss in class 0 images -1745.0393066 and step = 12 fake_pred 103.7404480 real_pred 280.7927856 temp_pred 191.7111664 1q 147.0945282 3q 228.7781982\n",
            "Discriminator loss in class 0 images -1780.0765381 and step = 13 fake_pred 94.8166580 real_pred 275.2683105 temp_pred 184.6585541 1q 139.2260895 3q 226.0621338\n",
            "Discriminator loss in class 0 images -1767.7574463 and step = 14 fake_pred 90.1685028 real_pred 269.4365845 temp_pred 179.3491821 1q 134.2781982 3q 222.4662781\n",
            "Discriminator loss in class 0 images -1796.9887695 and step = 15 fake_pred 87.5507202 real_pred 269.7934265 temp_pred 178.1574707 1q 132.3062897 3q 222.8432312\n",
            "Discriminator loss in class 0 images -1768.5683594 and step = 16 fake_pred 86.5162201 real_pred 266.1509705 temp_pred 175.4987030 1q 130.3359222 3q 218.6045227\n",
            "Discriminator loss in class 0 images -1807.1788330 and step = 17 fake_pred 81.7403870 real_pred 265.3170471 temp_pred 172.6293945 1q 126.4287109 3q 216.5633698\n",
            "Discriminator loss in class 0 images -1803.7253418 and step = 18 fake_pred 79.5956345 real_pred 262.7102661 temp_pred 170.2850342 1q 124.2064362 3q 213.6850433\n",
            "Discriminator loss in class 0 images -1796.6804199 and step = 19 fake_pred 76.3487854 real_pred 258.8044434 temp_pred 166.7612915 1q 120.8746796 3q 210.8147888\n",
            "Discriminator loss in class 0 images -1800.6884766 and step = 20 fake_pred 73.6212311 real_pred 256.4819031 temp_pred 164.2030792 1q 118.2365723 3q 208.7852325\n",
            "Generator loss in class 0 images 56.4782486 and step = 1 \n",
            "Generator loss in class 0 images 36.8788376 and step = 2 \n",
            "Generator loss in class 0 images 13.6159477 and step = 3 \n",
            "Generator loss in class 0 images -17.7918148 and step = 4 \n",
            "Generator loss in class 0 images -53.4672737 and step = 5 \n",
            "Generator loss in class 0 images -91.3366318 and step = 6 \n",
            "Generator loss in class 0 images -137.7841339 and step = 7 \n",
            "Generator loss in class 0 images -186.2258301 and step = 8 \n",
            "Generator loss in class 0 images -235.8358154 and step = 9 \n",
            "Generator loss in class 0 images -291.7418213 and step = 10 \n",
            "Generator loss in class 0 images -346.2041626 and step = 11 \n",
            "Generator loss in class 0 images -403.6366272 and step = 12 \n",
            "Generator loss in class 0 images -460.3435974 and step = 13 \n",
            "Generator loss in class 0 images -518.7879639 and step = 14 \n",
            "Generator loss in class 0 images -572.9626465 and step = 15 \n",
            "Generator loss in class 0 images -609.9754639 and step = 16 \n",
            "Generator loss in class 0 images -641.8212280 and step = 17 \n",
            "Generator loss in class 0 images -665.7020264 and step = 18 \n",
            "Generator loss in class 0 images -689.0548706 and step = 19 \n",
            "Generator loss in class 0 images -706.7077637 and step = 20 \n",
            "Generator loss in class 0 images -724.5367432 and step = 21 \n",
            "Generator loss in class 0 images -741.5772705 and step = 22 \n",
            "Generator loss in class 0 images -754.6613770 and step = 23 \n",
            "Generator loss in class 0 images -768.3323975 and step = 24 \n",
            "Generator loss in class 0 images -782.8358154 and step = 25 \n",
            "Generator loss in class 0 images -796.3260498 and step = 26 \n",
            "Generator loss in class 0 images -807.3861694 and step = 27 \n",
            "Generator loss in class 0 images -819.7492676 and step = 28 \n",
            "Generator loss in class 0 images -831.1493530 and step = 29 \n",
            "Generator loss in class 0 images -842.6239014 and step = 30 \n",
            "Generator loss in class 0 images -852.5792847 and step = 31 \n",
            "Generator loss in class 0 images -865.2377319 and step = 32 \n",
            "Generator loss in class 0 images -874.4763794 and step = 33 \n",
            "Generator loss in class 0 images -884.5511475 and step = 34 \n",
            "Generator loss in class 0 images -892.6417236 and step = 35 \n",
            "Generator loss in class 0 images -904.2877197 and step = 36 \n",
            "Generator loss in class 0 images -911.2681885 and step = 37 \n",
            "Generator loss in class 0 images -918.9446411 and step = 38 \n",
            "Generator loss in class 0 images -927.7734375 and step = 39 \n",
            "Generator loss in class 0 images -932.9757690 and step = 40 \n",
            "Epoch starting 20742\n",
            "Discriminator loss in class 0 images 434.3236389 and step = 1 fake_pred 94.2010193 real_pred 55.5039368 temp_pred 77.5194855 1q 86.4543381 3q -330.6200562\n",
            "Discriminator loss in class 0 images -2741.9118652 and step = 2 fake_pred -535.3342285 real_pred -258.6920776 temp_pred -397.1299438 1q -466.1969604 3q -357.8254395\n",
            "Discriminator loss in class 0 images -2855.2614746 and step = 3 fake_pred -573.0412598 real_pred -284.6525269 temp_pred -428.3294067 1q -500.0571289 3q -359.2610168\n",
            "Discriminator loss in class 0 images -2865.5173340 and step = 4 fake_pred -575.1115723 real_pred -284.0831299 temp_pred -428.0872192 1q -499.8273010 3q -344.2563477\n",
            "Discriminator loss in class 0 images -2870.0698242 and step = 5 fake_pred -561.2506104 real_pred -270.8549194 temp_pred -415.2365723 1q -486.9645386 3q -330.6028137\n",
            "Discriminator loss in class 0 images -2844.5363770 and step = 6 fake_pred -546.3529053 real_pred -258.7554321 temp_pred -401.8752441 1q -472.9617920 3q -317.5628052\n",
            "Discriminator loss in class 0 images -2834.2299805 and step = 7 fake_pred -530.8314209 real_pred -244.6854553 temp_pred -387.3780518 1q -458.2750549 3q -305.6775208\n",
            "Discriminator loss in class 0 images -2857.3388672 and step = 8 fake_pred -519.8230591 real_pred -231.6943665 temp_pred -375.9103394 1q -447.5509644 3q -299.1453857\n",
            "Discriminator loss in class 0 images -2868.8359375 and step = 9 fake_pred -516.4357910 real_pred -226.9901123 temp_pred -372.0057678 1q -444.2516785 3q -300.1605225\n",
            "Discriminator loss in class 0 images -2930.4533691 and step = 10 fake_pred -520.6696167 real_pred -225.1889648 temp_pred -373.0421143 1q -446.6709595 3q -300.8066406\n",
            "Discriminator loss in class 0 images -2903.8344727 and step = 11 fake_pred -521.7089844 real_pred -227.6423492 temp_pred -373.6732788 1q -446.1638489 3q -292.5220947\n",
            "Discriminator loss in class 0 images -2889.1196289 and step = 12 fake_pred -509.7040405 real_pred -216.6243896 temp_pred -361.9970703 1q -433.9278564 3q -279.1634216\n",
            "Discriminator loss in class 0 images -2880.7109375 and step = 13 fake_pred -496.4127502 real_pred -205.3696289 temp_pred -350.3834229 1q -422.1455078 3q -272.4467163\n",
            "Discriminator loss in class 0 images -2899.9394531 and step = 14 fake_pred -490.6866455 real_pred -197.9268799 temp_pred -344.1040039 1q -416.2504272 3q -269.8784485\n",
            "Discriminator loss in class 0 images -2912.9802246 and step = 15 fake_pred -487.9911194 real_pred -193.5198822 temp_pred -340.4227295 1q -412.6273804 3q -267.2428284\n",
            "Discriminator loss in class 0 images -2891.5322266 and step = 16 fake_pred -484.9501953 real_pred -192.6504669 temp_pred -338.6031494 1q -410.1228027 3q -267.0992432\n",
            "Discriminator loss in class 0 images -2873.2204590 and step = 17 fake_pred -482.8121338 real_pred -192.8831177 temp_pred -338.0215759 1q -409.3133240 3q -269.5432739\n",
            "Discriminator loss in class 0 images -2912.2775879 and step = 18 fake_pred -487.7037964 real_pred -194.0310059 temp_pred -341.1416931 1q -413.7327881 3q -271.7411804\n",
            "Discriminator loss in class 0 images -2920.4448242 and step = 19 fake_pred -492.0059814 real_pred -196.5337830 temp_pred -343.7529297 1q -416.1416931 3q -263.7247925\n",
            "Discriminator loss in class 0 images -2905.7253418 and step = 20 fake_pred -481.7574463 real_pred -186.7375946 temp_pred -333.3580322 1q -405.0812378 3q -250.1462250\n",
            "Generator loss in class 0 images 1875.6419678 and step = 1 \n",
            "Generator loss in class 0 images 1804.6489258 and step = 2 \n",
            "Generator loss in class 0 images 1716.1423340 and step = 3 \n",
            "Generator loss in class 0 images 1607.9467773 and step = 4 \n",
            "Generator loss in class 0 images 1495.1376953 and step = 5 \n",
            "Generator loss in class 0 images 1367.6738281 and step = 6 \n",
            "Generator loss in class 0 images 1232.8344727 and step = 7 \n",
            "Generator loss in class 0 images 1099.0791016 and step = 8 \n",
            "Generator loss in class 0 images 966.6558838 and step = 9 \n",
            "Generator loss in class 0 images 842.3613281 and step = 10 \n",
            "Generator loss in class 0 images 715.4075928 and step = 11 \n",
            "Generator loss in class 0 images 604.4132690 and step = 12 \n",
            "Generator loss in class 0 images 517.3723755 and step = 13 \n",
            "Generator loss in class 0 images 453.7211304 and step = 14 \n",
            "Generator loss in class 0 images 406.6703491 and step = 15 \n",
            "Generator loss in class 0 images 366.0343628 and step = 16 \n",
            "Generator loss in class 0 images 331.1082458 and step = 17 \n",
            "Generator loss in class 0 images 303.2091980 and step = 18 \n",
            "Generator loss in class 0 images 276.5379333 and step = 19 \n",
            "Generator loss in class 0 images 254.8343048 and step = 20 \n",
            "Generator loss in class 0 images 231.8665771 and step = 21 \n",
            "Generator loss in class 0 images 214.3265991 and step = 22 \n",
            "Generator loss in class 0 images 196.7061768 and step = 23 \n",
            "Generator loss in class 0 images 179.8229980 and step = 24 \n",
            "Generator loss in class 0 images 167.4777985 and step = 25 \n",
            "Generator loss in class 0 images 157.5626831 and step = 26 \n",
            "Generator loss in class 0 images 148.2181396 and step = 27 \n",
            "Generator loss in class 0 images 141.4451904 and step = 28 \n",
            "Generator loss in class 0 images 135.7324066 and step = 29 \n",
            "Generator loss in class 0 images 132.2596893 and step = 30 \n",
            "Generator loss in class 0 images 129.4917603 and step = 31 \n",
            "Generator loss in class 0 images 125.4883728 and step = 32 \n",
            "Generator loss in class 0 images 123.1561127 and step = 33 \n",
            "Generator loss in class 0 images 121.6762848 and step = 34 \n",
            "Generator loss in class 0 images 121.2118225 and step = 35 \n",
            "Generator loss in class 0 images 119.0619049 and step = 36 \n",
            "Generator loss in class 0 images 118.0810165 and step = 37 \n",
            "Generator loss in class 0 images 116.4058533 and step = 38 \n",
            "Generator loss in class 0 images 115.9963303 and step = 39 \n",
            "Generator loss in class 0 images 115.6679153 and step = 40 \n",
            "Epoch starting 20743\n",
            "Discriminator loss in class 0 images 557.1544189 and step = 1 fake_pred -11.4354839 real_pred -57.8036766 temp_pred -29.9699001 1q -18.3715096 3q 87.8362579\n",
            "Discriminator loss in class 0 images -876.9949951 and step = 2 fake_pred -1.4160159 real_pred 132.2261047 temp_pred 44.1695786 1q 7.2873530 3q 297.7736206\n",
            "Discriminator loss in class 0 images -1987.1258545 and step = 3 fake_pred 140.6562500 real_pred 346.1436157 temp_pred 240.1072693 1q 188.5511780 3q 345.1710815\n",
            "Discriminator loss in class 0 images -2104.2658691 and step = 4 fake_pred 180.0467834 real_pred 397.3337097 temp_pred 285.6875305 1q 230.5468597 3q 352.2955627\n",
            "Discriminator loss in class 0 images -2146.3603516 and step = 5 fake_pred 183.6394043 real_pred 405.8706970 temp_pred 291.2809143 1q 235.1077423 3q 340.5905151\n",
            "Discriminator loss in class 0 images -2204.3664551 and step = 6 fake_pred 170.8319397 real_pred 398.1783447 temp_pred 281.1568909 1q 224.1404114 3q 324.2619934\n",
            "Discriminator loss in class 0 images -2241.2678223 and step = 7 fake_pred 152.7338257 real_pred 383.0608521 temp_pred 264.7855835 1q 207.2701416 3q 306.1220703\n",
            "Discriminator loss in class 0 images -2243.8168945 and step = 8 fake_pred 133.2768555 real_pred 363.5406494 temp_pred 245.4655151 1q 187.9337311 3q 286.0579834\n",
            "Discriminator loss in class 0 images -2246.8962402 and step = 9 fake_pred 113.2182617 real_pred 343.6593628 temp_pred 225.6074219 1q 167.9154053 3q 267.5691223\n",
            "Discriminator loss in class 0 images -2274.6679688 and step = 10 fake_pred 93.6314545 real_pred 326.3084106 temp_pred 207.4752808 1q 149.1088409 3q 252.6991882\n",
            "Discriminator loss in class 0 images -2288.8886719 and step = 11 fake_pred 77.9114990 real_pred 311.4972229 temp_pred 192.4733887 1q 133.8899841 3q 241.2366638\n",
            "Discriminator loss in class 0 images -2307.9401855 and step = 12 fake_pred 66.3571091 real_pred 301.2301941 temp_pred 181.8887787 1q 123.0515137 3q 235.8455505\n",
            "Discriminator loss in class 0 images -2308.0915527 and step = 13 fake_pred 58.9549484 real_pred 293.2918701 temp_pred 174.5411987 1q 115.8619766 3q 231.5887451\n",
            "Discriminator loss in class 0 images -2307.8508301 and step = 14 fake_pred 56.4424858 real_pred 290.8827515 temp_pred 172.0087891 1q 113.2480774 3q 229.2729950\n",
            "Discriminator loss in class 0 images -2293.6838379 and step = 15 fake_pred 53.8339272 real_pred 287.2820740 temp_pred 168.6598206 1q 110.1052017 3q 224.7320862\n",
            "Discriminator loss in class 0 images -2281.8723145 and step = 16 fake_pred 49.9714279 real_pred 282.3814697 temp_pred 164.2255096 1q 105.8833466 3q 219.4449615\n",
            "Discriminator loss in class 0 images -2253.5427246 and step = 17 fake_pred 46.5891380 real_pred 276.1513977 temp_pred 159.4013519 1q 101.8180542 3q 214.6254883\n",
            "Discriminator loss in class 0 images -2279.2976074 and step = 18 fake_pred 42.3661041 real_pred 274.0222473 temp_pred 156.5162201 1q 98.3884277 3q 214.7495270\n",
            "Discriminator loss in class 0 images -2295.8820801 and step = 19 fake_pred 41.0235252 real_pred 274.0346680 temp_pred 156.0551147 1q 97.5803757 3q 216.8408966\n",
            "Discriminator loss in class 0 images -2313.8339844 and step = 20 fake_pred 41.1765442 real_pred 276.0137939 temp_pred 157.1129303 1q 98.1748810 3q 218.8613586\n",
            "Generator loss in class 0 images 135.2468567 and step = 1 \n",
            "Generator loss in class 0 images 134.9533997 and step = 2 \n",
            "Generator loss in class 0 images 133.3488159 and step = 3 \n",
            "Generator loss in class 0 images 130.7231140 and step = 4 \n",
            "Generator loss in class 0 images 128.4653015 and step = 5 \n",
            "Generator loss in class 0 images 124.9102707 and step = 6 \n",
            "Generator loss in class 0 images 122.5303955 and step = 7 \n",
            "Generator loss in class 0 images 117.3585052 and step = 8 \n",
            "Generator loss in class 0 images 113.3944702 and step = 9 \n",
            "Generator loss in class 0 images 107.8050232 and step = 10 \n",
            "Generator loss in class 0 images 100.5308228 and step = 11 \n",
            "Generator loss in class 0 images 92.8822937 and step = 12 \n",
            "Generator loss in class 0 images 84.0194321 and step = 13 \n",
            "Generator loss in class 0 images 73.0577469 and step = 14 \n",
            "Generator loss in class 0 images 61.4413757 and step = 15 \n",
            "Generator loss in class 0 images 47.4039993 and step = 16 \n",
            "Generator loss in class 0 images 32.7363510 and step = 17 \n",
            "Generator loss in class 0 images 17.1202965 and step = 18 \n",
            "Generator loss in class 0 images -1.7766604 and step = 19 \n",
            "Generator loss in class 0 images -19.6078720 and step = 20 \n",
            "Generator loss in class 0 images -39.0884628 and step = 21 \n",
            "Generator loss in class 0 images -59.6867561 and step = 22 \n",
            "Generator loss in class 0 images -79.9339066 and step = 23 \n",
            "Generator loss in class 0 images -103.7289276 and step = 24 \n",
            "Generator loss in class 0 images -123.6111374 and step = 25 \n",
            "Generator loss in class 0 images -148.3945923 and step = 26 \n",
            "Generator loss in class 0 images -173.4504395 and step = 27 \n",
            "Generator loss in class 0 images -196.7070007 and step = 28 \n",
            "Generator loss in class 0 images -222.6527405 and step = 29 \n",
            "Generator loss in class 0 images -248.2455750 and step = 30 \n",
            "Generator loss in class 0 images -271.6305237 and step = 31 \n",
            "Generator loss in class 0 images -297.9880371 and step = 32 \n",
            "Generator loss in class 0 images -321.3488770 and step = 33 \n",
            "Generator loss in class 0 images -340.6662292 and step = 34 \n",
            "Generator loss in class 0 images -362.3538818 and step = 35 \n",
            "Generator loss in class 0 images -377.5920410 and step = 36 \n",
            "Generator loss in class 0 images -388.8773193 and step = 37 \n",
            "Generator loss in class 0 images -395.4479675 and step = 38 \n",
            "Generator loss in class 0 images -400.5734558 and step = 39 \n",
            "Generator loss in class 0 images -404.9372559 and step = 40 \n",
            "Epoch starting 20744\n",
            "Discriminator loss in class 0 images 68.9279022 and step = 1 fake_pred 40.7055511 real_pred 36.1128349 temp_pred 38.0503960 1q 39.5479431 3q -148.7464447\n",
            "Discriminator loss in class 0 images -417.6239319 and step = 2 fake_pred -179.8513184 real_pred -136.2865448 temp_pred -158.8960419 1q -169.1995850 3q -249.7856445\n",
            "Discriminator loss in class 0 images -618.4278564 and step = 3 fake_pred -299.7727051 real_pred -235.5480042 temp_pred -267.1573181 1q -283.1217651 3q -284.0687561\n",
            "Discriminator loss in class 0 images -676.8641357 and step = 4 fake_pred -336.9622803 real_pred -266.3779907 temp_pred -300.6105957 1q -318.3970947 3q -291.8475342\n",
            "Discriminator loss in class 0 images -708.1129150 and step = 5 fake_pred -348.3894653 real_pred -274.4756165 temp_pred -310.1796875 1q -328.9117737 3q -293.8727722\n",
            "Discriminator loss in class 0 images -693.0078735 and step = 6 fake_pred -350.0576782 real_pred -277.4706726 temp_pred -312.3883972 1q -330.8417969 3q -294.0785828\n",
            "Discriminator loss in class 0 images -687.6867676 and step = 7 fake_pred -349.3120422 real_pred -277.2707214 temp_pred -311.8939819 1q -330.2240601 3q -293.3024902\n",
            "Discriminator loss in class 0 images -690.7346191 and step = 8 fake_pred -347.0573730 real_pred -274.7759399 temp_pred -309.5883789 1q -327.9412842 3q -290.8801270\n",
            "Discriminator loss in class 0 images -706.9100342 and step = 9 fake_pred -348.1554871 real_pred -274.2005615 temp_pred -309.8385010 1q -328.5808716 3q -290.6394653\n",
            "Discriminator loss in class 0 images -695.2799683 and step = 10 fake_pred -345.1629333 real_pred -272.4439392 temp_pred -307.4654541 1q -325.8292542 3q -287.8068848\n",
            "Discriminator loss in class 0 images -703.5729980 and step = 11 fake_pred -344.7672119 real_pred -271.2809143 temp_pred -306.8442383 1q -325.3068848 3q -287.2819214\n",
            "Discriminator loss in class 0 images -703.7996826 and step = 12 fake_pred -342.4442139 real_pred -269.0108032 temp_pred -304.5694275 1q -323.0547180 3q -285.2608948\n",
            "Discriminator loss in class 0 images -692.3056641 and step = 13 fake_pred -339.9690552 real_pred -267.8121338 temp_pred -302.8326416 1q -320.9875183 3q -283.9989624\n",
            "Discriminator loss in class 0 images -717.9089966 and step = 14 fake_pred -340.8328247 real_pred -266.2055054 temp_pred -302.5452271 1q -321.3656921 3q -284.0783691\n",
            "Discriminator loss in class 0 images -702.1687622 and step = 15 fake_pred -341.0277710 real_pred -267.8929443 temp_pred -303.5272827 1q -321.9898071 3q -286.3294678\n",
            "Discriminator loss in class 0 images -714.5505371 and step = 16 fake_pred -341.8241577 real_pred -267.5204468 temp_pred -303.7680054 1q -322.5586853 3q -286.8881836\n",
            "Discriminator loss in class 0 images -722.9868164 and step = 17 fake_pred -344.3613281 real_pred -269.1682129 temp_pred -305.7845764 1q -324.7979736 3q -288.7334595\n",
            "Discriminator loss in class 0 images -724.4125366 and step = 18 fake_pred -346.6067200 real_pred -271.1336060 temp_pred -307.7231140 1q -326.8449707 3q -289.9564819\n",
            "Discriminator loss in class 0 images -734.1370850 and step = 19 fake_pred -348.2136230 real_pred -271.8223572 temp_pred -308.9174805 1q -328.1833496 3q -290.6143494\n",
            "Discriminator loss in class 0 images -728.2297974 and step = 20 fake_pred -348.9404907 real_pred -272.9501343 temp_pred -309.7091064 1q -328.8754272 3q -290.6719360\n",
            "Generator loss in class 0 images 334.3710632 and step = 1 \n",
            "Generator loss in class 0 images 320.6364441 and step = 2 \n",
            "Generator loss in class 0 images 300.9946899 and step = 3 \n",
            "Generator loss in class 0 images 279.8776855 and step = 4 \n",
            "Generator loss in class 0 images 255.9448090 and step = 5 \n",
            "Generator loss in class 0 images 234.2739716 and step = 6 \n",
            "Generator loss in class 0 images 211.5308838 and step = 7 \n",
            "Generator loss in class 0 images 196.2422180 and step = 8 \n",
            "Generator loss in class 0 images 184.4557800 and step = 9 \n",
            "Generator loss in class 0 images 175.8635559 and step = 10 \n",
            "Generator loss in class 0 images 169.6102142 and step = 11 \n",
            "Generator loss in class 0 images 166.5205383 and step = 12 \n",
            "Generator loss in class 0 images 163.9059143 and step = 13 \n",
            "Generator loss in class 0 images 161.9641113 and step = 14 \n",
            "Generator loss in class 0 images 159.8998718 and step = 15 \n",
            "Generator loss in class 0 images 158.8268280 and step = 16 \n",
            "Generator loss in class 0 images 157.8463898 and step = 17 \n",
            "Generator loss in class 0 images 155.8810120 and step = 18 \n",
            "Generator loss in class 0 images 155.2680664 and step = 19 \n",
            "Generator loss in class 0 images 153.7359467 and step = 20 \n",
            "Generator loss in class 0 images 152.9637604 and step = 21 \n",
            "Generator loss in class 0 images 153.2907257 and step = 22 \n",
            "Generator loss in class 0 images 151.9780121 and step = 23 \n",
            "Generator loss in class 0 images 151.3670654 and step = 24 \n",
            "Generator loss in class 0 images 151.3673401 and step = 25 \n",
            "Generator loss in class 0 images 150.9376373 and step = 26 \n",
            "Generator loss in class 0 images 150.1908569 and step = 27 \n",
            "Generator loss in class 0 images 149.7772217 and step = 28 \n",
            "Generator loss in class 0 images 149.2022400 and step = 29 \n",
            "Generator loss in class 0 images 149.0939941 and step = 30 \n",
            "Generator loss in class 0 images 148.0535583 and step = 31 \n",
            "Generator loss in class 0 images 147.5051727 and step = 32 \n",
            "Generator loss in class 0 images 147.6743927 and step = 33 \n",
            "Generator loss in class 0 images 147.4866943 and step = 34 \n",
            "Generator loss in class 0 images 146.4732666 and step = 35 \n",
            "Generator loss in class 0 images 146.7244110 and step = 36 \n",
            "Generator loss in class 0 images 146.3490448 and step = 37 \n",
            "Generator loss in class 0 images 145.6641998 and step = 38 \n",
            "Generator loss in class 0 images 145.5603943 and step = 39 \n",
            "Generator loss in class 0 images 144.9233093 and step = 40 \n",
            "Epoch starting 20745\n",
            "Discriminator loss in class 0 images 31.2573662 and step = 1 fake_pred -14.5383778 real_pred -15.8876400 temp_pred -15.4111834 1q -14.8398829 3q 101.8862457\n",
            "Discriminator loss in class 0 images -570.8927002 and step = 2 fake_pred 58.1867599 real_pred 117.3357620 temp_pred 86.8039246 1q 72.1936646 3q 140.9087982\n",
            "Discriminator loss in class 0 images -780.0341797 and step = 3 fake_pred 79.6984558 real_pred 159.8610229 temp_pred 119.8503036 1q 99.6030731 3q 150.5765381\n",
            "Discriminator loss in class 0 images -870.6251221 and step = 4 fake_pred 84.0430756 real_pred 173.5364075 temp_pred 129.3014679 1q 106.5757294 3q 158.2539062\n",
            "Discriminator loss in class 0 images -883.7128296 and step = 5 fake_pred 88.2434082 real_pred 179.2365112 temp_pred 134.3814392 1q 111.2078857 3q 162.8410950\n",
            "Discriminator loss in class 0 images -880.9821167 and step = 6 fake_pred 93.6830597 real_pred 184.3509674 temp_pred 139.4671021 1q 116.3715744 3q 166.5466156\n",
            "Discriminator loss in class 0 images -880.2580566 and step = 7 fake_pred 97.4603348 real_pred 187.9896393 temp_pred 142.9402313 1q 119.9081039 3q 168.3824158\n",
            "Discriminator loss in class 0 images -869.0045776 and step = 8 fake_pred 99.8867264 real_pred 189.3288269 temp_pred 144.8009949 1q 122.0024643 3q 169.4673157\n",
            "Discriminator loss in class 0 images -881.9597778 and step = 9 fake_pred 101.4311523 real_pred 192.1112213 temp_pred 146.8510132 1q 123.7330780 3q 170.6203461\n",
            "Discriminator loss in class 0 images -878.3951416 and step = 10 fake_pred 102.1488037 real_pred 192.4243164 temp_pred 147.2452698 1q 124.2099915 3q 169.1915741\n",
            "Discriminator loss in class 0 images -880.0863037 and step = 11 fake_pred 100.6448975 real_pred 191.1494598 temp_pred 145.8869324 1q 122.7607880 3q 166.9038391\n",
            "Discriminator loss in class 0 images -872.8181152 and step = 12 fake_pred 97.4855957 real_pred 187.1776733 temp_pred 142.3967438 1q 119.4996643 3q 162.6192780\n",
            "Discriminator loss in class 0 images -877.0202026 and step = 13 fake_pred 93.9220047 real_pred 184.0883484 temp_pred 139.1968689 1q 116.2121964 3q 160.6498718\n",
            "Discriminator loss in class 0 images -870.7955933 and step = 14 fake_pred 92.2804871 real_pred 181.8128510 temp_pred 137.5218506 1q 114.6892853 3q 161.1353455\n",
            "Discriminator loss in class 0 images -857.1513062 and step = 15 fake_pred 93.4741135 real_pred 181.6097412 temp_pred 138.1131287 1q 115.6232529 3q 162.3513184\n",
            "Discriminator loss in class 0 images -879.1791992 and step = 16 fake_pred 94.0250702 real_pred 184.3115845 temp_pred 139.5270996 1q 116.5281448 3q 164.1123047\n",
            "Discriminator loss in class 0 images -876.8110352 and step = 17 fake_pred 96.3107758 real_pred 186.4002838 temp_pred 141.5152740 1q 118.5725021 3q 164.7921448\n",
            "Discriminator loss in class 0 images -881.0789795 and step = 18 fake_pred 95.8807678 real_pred 186.4611816 temp_pred 141.1836700 1q 118.1393280 3q 163.7597961\n",
            "Discriminator loss in class 0 images -882.2478027 and step = 19 fake_pred 94.2863846 real_pred 184.9034119 temp_pred 139.6683960 1q 116.5946884 3q 162.2843475\n",
            "Discriminator loss in class 0 images -882.1852417 and step = 20 fake_pred 94.0646439 real_pred 184.5492706 temp_pred 139.5236206 1q 116.4374237 3q 163.1677704\n",
            "Generator loss in class 0 images -178.8716125 and step = 1 \n",
            "Generator loss in class 0 images -196.8424225 and step = 2 \n",
            "Generator loss in class 0 images -222.1333313 and step = 3 \n",
            "Generator loss in class 0 images -250.8919373 and step = 4 \n",
            "Generator loss in class 0 images -280.3042603 and step = 5 \n",
            "Generator loss in class 0 images -315.8643799 and step = 6 \n",
            "Generator loss in class 0 images -347.5816040 and step = 7 \n",
            "Generator loss in class 0 images -381.6555481 and step = 8 \n",
            "Generator loss in class 0 images -411.1939087 and step = 9 \n",
            "Generator loss in class 0 images -435.8510742 and step = 10 \n",
            "Generator loss in class 0 images -453.8901367 and step = 11 \n",
            "Generator loss in class 0 images -466.3195496 and step = 12 \n",
            "Generator loss in class 0 images -474.8121338 and step = 13 \n",
            "Generator loss in class 0 images -484.7043457 and step = 14 \n",
            "Generator loss in class 0 images -490.5802917 and step = 15 \n",
            "Generator loss in class 0 images -497.0311890 and step = 16 \n",
            "Generator loss in class 0 images -503.1421509 and step = 17 \n",
            "Generator loss in class 0 images -507.1447144 and step = 18 \n",
            "Generator loss in class 0 images -513.6685181 and step = 19 \n",
            "Generator loss in class 0 images -515.7708740 and step = 20 \n",
            "Generator loss in class 0 images -521.1838379 and step = 21 \n",
            "Generator loss in class 0 images -526.1663818 and step = 22 \n",
            "Generator loss in class 0 images -529.8439941 and step = 23 \n",
            "Generator loss in class 0 images -530.0906982 and step = 24 \n",
            "Generator loss in class 0 images -536.4120483 and step = 25 \n",
            "Generator loss in class 0 images -538.3926392 and step = 26 \n",
            "Generator loss in class 0 images -541.2808838 and step = 27 \n",
            "Generator loss in class 0 images -545.2623901 and step = 28 \n",
            "Generator loss in class 0 images -547.2532959 and step = 29 \n",
            "Generator loss in class 0 images -550.1396484 and step = 30 \n",
            "Generator loss in class 0 images -554.1386719 and step = 31 \n",
            "Generator loss in class 0 images -557.6679688 and step = 32 \n",
            "Generator loss in class 0 images -556.9849854 and step = 33 \n",
            "Generator loss in class 0 images -562.5792847 and step = 34 \n",
            "Generator loss in class 0 images -563.7332764 and step = 35 \n",
            "Generator loss in class 0 images -565.6376953 and step = 36 \n",
            "Generator loss in class 0 images -571.0097656 and step = 37 \n",
            "Generator loss in class 0 images -570.4332275 and step = 38 \n",
            "Generator loss in class 0 images -574.1472778 and step = 39 \n",
            "Generator loss in class 0 images -575.0432129 and step = 40 \n",
            "Epoch starting 20746\n",
            "Discriminator loss in class 0 images 178.9335938 and step = 1 fake_pred 57.8720474 real_pred 42.7810898 temp_pred 51.7162933 1q 54.9627037 3q -295.9217529\n",
            "Discriminator loss in class 0 images -1871.2148438 and step = 2 fake_pred -437.2301636 real_pred -247.7788544 temp_pred -342.0539246 1q -389.4108582 3q -329.3468018\n",
            "Discriminator loss in class 0 images -2018.8576660 and step = 3 fake_pred -482.9437561 real_pred -278.2876587 temp_pred -379.7135620 1q -431.0389404 3q -335.8942261\n",
            "Discriminator loss in class 0 images -2045.8056641 and step = 4 fake_pred -491.0607300 real_pred -283.1209412 temp_pred -385.7398376 1q -437.6715088 3q -329.5568542\n",
            "Discriminator loss in class 0 images -2013.0634766 and step = 5 fake_pred -484.8899231 real_pred -279.9357300 temp_pred -380.9528198 1q -431.9798584 3q -321.1248169\n",
            "Discriminator loss in class 0 images -2019.9116211 and step = 6 fake_pred -473.4306030 real_pred -268.3912354 temp_pred -369.8567200 1q -421.0053711 3q -311.0232849\n",
            "Discriminator loss in class 0 images -2000.2486572 and step = 7 fake_pred -464.1932983 real_pred -261.5385742 temp_pred -362.2195435 1q -412.8787231 3q -306.0773010\n",
            "Discriminator loss in class 0 images -2019.9268799 and step = 8 fake_pred -458.4543457 real_pred -253.8560486 temp_pred -355.6326599 1q -406.8211060 3q -300.9445190\n",
            "Discriminator loss in class 0 images -2027.0181885 and step = 9 fake_pred -456.0348511 real_pred -250.6994324 temp_pred -352.7910461 1q -404.1580200 3q -299.2064209\n",
            "Discriminator loss in class 0 images -2025.8914795 and step = 10 fake_pred -453.5849609 real_pred -248.3598022 temp_pred -350.3576660 1q -401.6466370 3q -297.4958496\n",
            "Discriminator loss in class 0 images -2035.4387207 and step = 11 fake_pred -452.0520020 real_pred -245.7448120 temp_pred -348.1479187 1q -399.6394958 3q -294.7004089\n",
            "Discriminator loss in class 0 images -2051.5708008 and step = 12 fake_pred -449.6388550 real_pred -241.6322021 temp_pred -344.8725891 1q -396.5928650 3q -290.3947754\n",
            "Discriminator loss in class 0 images -2034.0117188 and step = 13 fake_pred -445.9719543 real_pred -239.4319763 temp_pred -341.7810974 1q -392.8815308 3q -286.2115479\n",
            "Discriminator loss in class 0 images -2015.3831787 and step = 14 fake_pred -440.1163940 real_pred -235.7423553 temp_pred -337.2663269 1q -387.8941345 3q -284.0356140\n",
            "Discriminator loss in class 0 images -2037.2017822 and step = 15 fake_pred -438.4900513 real_pred -231.8869629 temp_pred -334.5340576 1q -385.6815491 3q -280.9473267\n",
            "Discriminator loss in class 0 images -2047.7734375 and step = 16 fake_pred -435.1948242 real_pred -226.1742554 temp_pred -329.4164734 1q -380.4390259 3q -269.4829712\n",
            "Discriminator loss in class 0 images -2009.8211670 and step = 17 fake_pred -422.6086426 real_pred -215.7513580 temp_pred -317.4388733 1q -367.0163574 3q -256.3045959\n",
            "Discriminator loss in class 0 images -1993.5756836 and step = 18 fake_pred -407.3687439 real_pred -204.9153595 temp_pred -305.8118286 1q -355.1365356 3q -255.1547852\n",
            "Discriminator loss in class 0 images -2027.4000244 and step = 19 fake_pred -407.1700439 real_pred -201.9460297 temp_pred -305.1218262 1q -355.6591797 3q -262.5374451\n",
            "Discriminator loss in class 0 images -2055.5822754 and step = 20 fake_pred -418.0082397 real_pred -209.3434753 temp_pred -313.3468018 1q -364.2658997 3q -262.6914062\n",
            "Generator loss in class 0 images 1236.2792969 and step = 1 \n",
            "Generator loss in class 0 images 1183.4556885 and step = 2 \n",
            "Generator loss in class 0 images 1117.1883545 and step = 3 \n",
            "Generator loss in class 0 images 1039.5791016 and step = 4 \n",
            "Generator loss in class 0 images 953.6028442 and step = 5 \n",
            "Generator loss in class 0 images 867.6565552 and step = 6 \n",
            "Generator loss in class 0 images 777.5051880 and step = 7 \n",
            "Generator loss in class 0 images 687.4716797 and step = 8 \n",
            "Generator loss in class 0 images 608.2731934 and step = 9 \n",
            "Generator loss in class 0 images 526.8107910 and step = 10 \n",
            "Generator loss in class 0 images 456.0992432 and step = 11 \n",
            "Generator loss in class 0 images 403.2879944 and step = 12 \n",
            "Generator loss in class 0 images 367.7947388 and step = 13 \n",
            "Generator loss in class 0 images 339.9345398 and step = 14 \n",
            "Generator loss in class 0 images 318.1777954 and step = 15 \n",
            "Generator loss in class 0 images 298.2651367 and step = 16 \n",
            "Generator loss in class 0 images 280.9595642 and step = 17 \n",
            "Generator loss in class 0 images 267.2373657 and step = 18 \n",
            "Generator loss in class 0 images 254.1599731 and step = 19 \n",
            "Generator loss in class 0 images 241.8221283 and step = 20 \n",
            "Generator loss in class 0 images 229.9373627 and step = 21 \n",
            "Generator loss in class 0 images 221.3896942 and step = 22 \n",
            "Generator loss in class 0 images 211.0352783 and step = 23 \n",
            "Generator loss in class 0 images 202.2228851 and step = 24 \n",
            "Generator loss in class 0 images 194.0781250 and step = 25 \n",
            "Generator loss in class 0 images 186.8399353 and step = 26 \n",
            "Generator loss in class 0 images 180.4024506 and step = 27 \n",
            "Generator loss in class 0 images 174.1572876 and step = 28 \n",
            "Generator loss in class 0 images 167.6485443 and step = 29 \n",
            "Generator loss in class 0 images 162.1902771 and step = 30 \n",
            "Generator loss in class 0 images 157.4310608 and step = 31 \n",
            "Generator loss in class 0 images 153.4975586 and step = 32 \n",
            "Generator loss in class 0 images 150.1019592 and step = 33 \n",
            "Generator loss in class 0 images 148.5457764 and step = 34 \n",
            "Generator loss in class 0 images 145.3651428 and step = 35 \n",
            "Generator loss in class 0 images 143.8597717 and step = 36 \n",
            "Generator loss in class 0 images 142.5607910 and step = 37 \n",
            "Generator loss in class 0 images 141.4739075 and step = 38 \n",
            "Generator loss in class 0 images 139.0910492 and step = 39 \n",
            "Generator loss in class 0 images 138.9616394 and step = 40 \n",
            "Epoch starting 20747\n",
            "Discriminator loss in class 0 images 382.8614502 and step = 1 fake_pred -13.8170395 real_pred -46.5394783 temp_pred -26.9795303 1q -19.7572784 3q 100.0032883\n",
            "Discriminator loss in class 0 images -1065.7932129 and step = 2 fake_pred -1.3830636 real_pred 143.7570801 temp_pred 54.6784630 1q 12.8496876 3q 349.1707764\n",
            "Discriminator loss in class 0 images -1901.3977051 and step = 3 fake_pred 193.8964539 real_pred 394.3548584 temp_pred 288.9373169 1q 238.8807831 3q 387.9713135\n",
            "Discriminator loss in class 0 images -1950.6727295 and step = 4 fake_pred 233.4595947 real_pred 437.2442322 temp_pred 331.3522339 1q 279.7039185 3q 394.7482910\n",
            "Discriminator loss in class 0 images -1979.8968506 and step = 5 fake_pred 238.0668945 real_pred 445.2423096 temp_pred 337.3524170 1q 284.9888306 3q 383.9666748\n",
            "Discriminator loss in class 0 images -2002.1817627 and step = 6 fake_pred 227.7691650 real_pred 436.7052002 temp_pred 327.9707642 1q 275.5643616 3q 367.0718079\n",
            "Discriminator loss in class 0 images -2062.5266113 and step = 7 fake_pred 208.3644714 real_pred 422.1094360 temp_pred 311.5010376 1q 258.0640869 3q 349.1224365\n",
            "Discriminator loss in class 0 images -2083.7553711 and step = 8 fake_pred 188.1522522 real_pred 403.5207520 temp_pred 292.3343506 1q 238.5221252 3q 329.1525879\n",
            "Discriminator loss in class 0 images -2099.2666016 and step = 9 fake_pred 167.3981171 real_pred 383.8204956 temp_pred 272.4041138 1q 218.2326050 3q 309.4149170\n",
            "Discriminator loss in class 0 images -2130.8364258 and step = 10 fake_pred 146.9928131 real_pred 366.6009521 temp_pred 253.5797729 1q 198.6031342 3q 292.2659302\n",
            "Discriminator loss in class 0 images -2122.7006836 and step = 11 fake_pred 126.6571655 real_pred 344.3321533 temp_pred 232.8819733 1q 178.3150024 3q 273.2284851\n",
            "Discriminator loss in class 0 images -2152.2565918 and step = 12 fake_pred 111.1916962 real_pred 331.0805664 temp_pred 218.9269104 1q 163.7966003 3q 263.1835938\n",
            "Discriminator loss in class 0 images -2169.6394043 and step = 13 fake_pred 98.4293594 real_pred 319.2348633 temp_pred 207.0965118 1q 151.7546387 3q 255.4868317\n",
            "Discriminator loss in class 0 images -2148.2060547 and step = 14 fake_pred 90.7581482 real_pred 309.2535400 temp_pred 198.3943176 1q 143.6031342 3q 248.2895355\n",
            "Discriminator loss in class 0 images -2145.7102051 and step = 15 fake_pred 84.7411804 real_pred 303.2162781 temp_pred 192.2578430 1q 137.3769379 3q 242.9292908\n",
            "Discriminator loss in class 0 images -2156.2370605 and step = 16 fake_pred 78.9639282 real_pred 298.6303711 temp_pred 186.9904480 1q 131.7857666 3q 238.3629761\n",
            "Discriminator loss in class 0 images -2137.7092285 and step = 17 fake_pred 74.2896576 real_pred 291.8671875 temp_pred 181.3956909 1q 126.7194977 3q 233.1091614\n",
            "Discriminator loss in class 0 images -2153.5629883 and step = 18 fake_pred 69.6346130 real_pred 288.5044556 temp_pred 177.5730438 1q 122.6067581 3q 231.8360596\n",
            "Discriminator loss in class 0 images -2156.3349609 and step = 19 fake_pred 67.7067871 real_pred 286.5101318 temp_pred 175.8384094 1q 120.9273834 3q 232.2226257\n",
            "Discriminator loss in class 0 images -2165.9279785 and step = 20 fake_pred 68.3820419 real_pred 288.2313538 temp_pred 177.0083618 1q 121.8418884 3q 234.9118805\n",
            "Generator loss in class 0 images 119.3591156 and step = 1 \n",
            "Generator loss in class 0 images 114.6450500 and step = 2 \n",
            "Generator loss in class 0 images 106.8164673 and step = 3 \n",
            "Generator loss in class 0 images 94.3153534 and step = 4 \n",
            "Generator loss in class 0 images 79.7527466 and step = 5 \n",
            "Generator loss in class 0 images 61.8788490 and step = 6 \n",
            "Generator loss in class 0 images 42.2022057 and step = 7 \n",
            "Generator loss in class 0 images 17.7962875 and step = 8 \n",
            "Generator loss in class 0 images -11.5441942 and step = 9 \n",
            "Generator loss in class 0 images -41.2739182 and step = 10 \n",
            "Generator loss in class 0 images -75.5968475 and step = 11 \n",
            "Generator loss in class 0 images -107.0136948 and step = 12 \n",
            "Generator loss in class 0 images -144.5327911 and step = 13 \n",
            "Generator loss in class 0 images -181.9630737 and step = 14 \n",
            "Generator loss in class 0 images -226.6078491 and step = 15 \n",
            "Generator loss in class 0 images -265.8770752 and step = 16 \n",
            "Generator loss in class 0 images -311.7094727 and step = 17 \n",
            "Generator loss in class 0 images -355.9228821 and step = 18 \n",
            "Generator loss in class 0 images -399.2743530 and step = 19 \n",
            "Generator loss in class 0 images -443.2060242 and step = 20 \n",
            "Generator loss in class 0 images -489.1351929 and step = 21 \n",
            "Generator loss in class 0 images -526.9299316 and step = 22 \n",
            "Generator loss in class 0 images -558.1298218 and step = 23 \n",
            "Generator loss in class 0 images -582.9293823 and step = 24 \n",
            "Generator loss in class 0 images -599.1553345 and step = 25 \n",
            "Generator loss in class 0 images -613.3676758 and step = 26 \n",
            "Generator loss in class 0 images -624.9603882 and step = 27 \n",
            "Generator loss in class 0 images -637.7404175 and step = 28 \n",
            "Generator loss in class 0 images -647.5778198 and step = 29 \n",
            "Generator loss in class 0 images -656.6036377 and step = 30 \n",
            "Generator loss in class 0 images -665.4937744 and step = 31 \n",
            "Generator loss in class 0 images -671.7658081 and step = 32 \n",
            "Generator loss in class 0 images -679.8975220 and step = 33 \n",
            "Generator loss in class 0 images -686.0535278 and step = 34 \n",
            "Generator loss in class 0 images -693.3024902 and step = 35 \n",
            "Generator loss in class 0 images -697.7238770 and step = 36 \n",
            "Generator loss in class 0 images -704.1772461 and step = 37 \n",
            "Generator loss in class 0 images -710.1734009 and step = 38 \n",
            "Generator loss in class 0 images -715.8262939 and step = 39 \n",
            "Generator loss in class 0 images -721.1291504 and step = 40 \n",
            "Epoch starting 20748\n",
            "Discriminator loss in class 0 images 241.6116028 and step = 1 fake_pred 72.6878510 real_pred 51.6394882 temp_pred 63.7573586 1q 68.3748932 3q -288.7430420\n",
            "Discriminator loss in class 0 images -1695.7753906 and step = 2 fake_pred -416.8930054 real_pred -244.9489746 temp_pred -330.4254761 1q -373.3583374 3q -330.8233643\n",
            "Discriminator loss in class 0 images -1871.4516602 and step = 3 fake_pred -473.8771973 real_pred -283.8530884 temp_pred -377.8491516 1q -425.5794678 3q -337.7630310\n",
            "Discriminator loss in class 0 images -1889.2044678 and step = 4 fake_pred -481.4768982 real_pred -289.3111267 temp_pred -384.0493164 1q -432.3008423 3q -333.0465698\n",
            "Discriminator loss in class 0 images -1866.4437256 and step = 5 fake_pred -477.3468018 real_pred -287.4656677 temp_pred -381.0715332 1q -428.7887573 3q -328.4434204\n",
            "Discriminator loss in class 0 images -1879.9091797 and step = 6 fake_pred -472.1194458 real_pred -281.2449951 temp_pred -375.6604614 1q -423.6530151 3q -323.1947021\n",
            "Discriminator loss in class 0 images -1878.8281250 and step = 7 fake_pred -466.9927368 real_pred -276.3019714 temp_pred -370.6862488 1q -418.6832275 3q -318.6702576\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "epochs = 0\n",
        "\n",
        "save_interval=20\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/gan_models\"\n",
        "\n",
        "#normalize_each_param(discriminator)\n",
        "\n",
        "discriminator_ema = init_ema_model(discriminator).cuda()  # EMA model has same architecture\n",
        "\n",
        "\n",
        "for epoch in range(20740, epochs+280004):\n",
        "\n",
        "\n",
        "    checkpoint_dir = \"/content/drive/MyDrive/gan_models\"\n",
        "\n",
        "    if (epoch)%save_interval == 0:\n",
        "\n",
        "      checkpoint_path =f\"{checkpoint_dir}/generator_checkpoint_epoch_{epoch}.pth\"\n",
        "\n",
        "\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': generator.state_dict(),\n",
        "            'optimizer_state_dict': g_optimizer.state_dict(),\n",
        "            \"rng_state\": torch.get_rng_state(),\n",
        "            \"numpy_rng_state\": np.random.get_state(),\n",
        "            \"python_rng_state\": random.getstate(),\n",
        "            \"cuda_rng_state\": torch.cuda.get_rng_state()\n",
        "        }, checkpoint_path)\n",
        "      checkpoint_path = f\"{checkpoint_dir}/discriminator_checkpoint_{epoch}.pth\"\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': discriminator.state_dict(),\n",
        "            'optimizer_state_dict': d_optimizer.state_dict()\n",
        "        }, checkpoint_path)\n",
        "\n",
        "      print(f\"Model checkpoint saved to {checkpoint_path}\")\n",
        "\n",
        "\n",
        "    print(\"Epoch starting {}\".format(epoch))\n",
        "    steps = 0\n",
        "\n",
        "    d_optimizer = torch.optim.SGD(discriminator.parameters(), lr=0.00001, momentum=0.7, nesterov=True)\n",
        "\n",
        "    try:\n",
        "        #discriminator_loss = torch.tensor(0.0).cuda()\n",
        "        while True:\n",
        "            steps += 1\n",
        "            if steps > 20:\n",
        "                break\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "              ims, _ = next(dataloader_iter)\n",
        "\n",
        "            except StopIteration:\n",
        "              dataloader_first = DataLoader(dataset_first, batch_size=2048, shuffle=True)\n",
        "              dataloader_iter = iter(dataloader_first)\n",
        "              ims, _ = next(dataloader_iter)\n",
        "\n",
        "\n",
        "            real_pred = discriminator(ims)\n",
        "\n",
        "            gauss = torch.randn(len(ims), 5, device=\"cuda\")\n",
        "\n",
        "            fake_images = generator(gauss)\n",
        "\n",
        "            fake_images = torch.tensor(fake_images, requires_grad=False).cuda().detach()\n",
        "\n",
        "            fake_images_labeled = fake_images\n",
        "            fake_pred = discriminator(fake_images_labeled)\n",
        "\n",
        "\n",
        "            temp_pred = discriminator(0.5*ims+0.5*fake_images_labeled)\n",
        "\n",
        "            temp_pred2 = discriminator(0.25*ims+0.75*fake_images_labeled)\n",
        "\n",
        "            ls = 10*(fake_pred-real_pred).mean() + 10*((temp_pred-0.5*real_pred-0.5*fake_pred).abs().mean())+ 10*((temp_pred2-0.25*real_pred-0.75*fake_pred).abs().mean())\n",
        "\n",
        "\n",
        "            ls.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            print(\"Discriminator loss in class 0 images {:.7f} and step = {} fake_pred {:.7f} real_pred {:.7f} temp_pred {:.7f} 1q {:.7f} 3q {:.7f}\".format(ls, steps, np.float64(fake_pred.mean().cpu()), np.float64(real_pred.mean().cpu()), np.float64(temp_pred.mean().cpu()), np.float64(temp_pred2.mean().cpu()), np.float64(discriminator(0.75*ims+0.25*fake_images_labeled).mean().cpu())))\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "\n",
        "    update_ema_model(discriminator, discriminator_ema)\n",
        "    load_ema_to_model(discriminator, discriminator_ema)\n",
        "\n",
        "\n",
        "    #generator_ema = init_ema_model(generator).cuda()  # EMA model has same architecture\n",
        "\n",
        "    steps = 0\n",
        "\n",
        "    g_optimizer = torch.optim.SGD(generator.parameters(), lr=0.00001, momentum=0.7, nesterov=True)\n",
        "\n",
        "\n",
        "    while True:\n",
        "        steps += 1\n",
        "        if steps > 40:\n",
        "            break\n",
        "\n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        gauss = torch.randn(2048, 5, device=\"cuda\")\n",
        "\n",
        "        fake_images = generator(gauss)\n",
        "\n",
        "\n",
        "        fake_images_labeled = fake_images\n",
        "\n",
        "\n",
        "        fake_pred = discriminator(fake_images_labeled)\n",
        "\n",
        "        ls = -10*(fake_pred).mean()\n",
        "        ls.backward()\n",
        "\n",
        "            #normalize_each_param(discriminator)\n",
        "\n",
        "        g_optimizer.step()\n",
        "        print(\"Generator loss in class 0 images {:.7f} and step = {} \".format(ls, steps))\n",
        "\n",
        "\n",
        "\n",
        "    #update_ema_model(generator, generator_ema, decay=0.85)\n",
        "    #load_ema_to_model(generator, generator_ema)\n",
        "\n",
        "    if (epoch)%save_interval==0:\n",
        "        with torch.no_grad():\n",
        "\n",
        "            gauss = torch.randn(100, 5, device=\"cuda\")\n",
        "\n",
        "            fake_images = generator(gauss)\n",
        "\n",
        "            fake_images = torch.tensor(fake_images, requires_grad=False).cuda().detach()\n",
        "\n",
        "            fake_images_labeled = fake_images\n",
        "            dump_images(torch.clone(fake_images_labeled))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}